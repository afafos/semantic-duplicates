1. Взял датасеты из того, что присылали в json. Посмотрел разметки по каждому человеку.
Статистика эта в файле analyze_duplicates.py (вывод в консоль).
Также в этом скрипте создается согласованная разметка osokina и popov (так как у них больше всего размеченных новостей). Я взял согласованные разметки от них и создал датасет для теста в agreed_annotations_osokina_popov.json.

2. Так как размеченных новостей в предложенных датасетах мало, то я поискал какие есть датасеты еще. 
Нашел 
Источники: merionum/ru_paraphraser, GEM/opusparcus (RU), cointegrated/ru-paraphrase-NMT-Leipzig, viacheslavshalamov/russian-news-paraphrases-2020 (Kaggle).
- ru_paraphraser - там собраны новостные заголовки на русском языке с разметкой - дубль или нет
1 = точный парафраз (дубликат)
0 = near (близкий/похожий, но не точный) - по умолчанию удаляем (если нет флага --near-as-positive)
-1 = не парафраз (не дубликат)

- opusparcus - датасет парафразов на русском и не только
annot_score:  1.0 ---- 2.0 ---- [2.5] ---- 3.0 ---- 4.0
                |         |       X        |         |
              не дубл.  не дубл. удалён  дубл.    дубл.
              (label=0) (label=0)        (label=1) (label=1)
              
neg_threshold=2.0 ↑               ↑ pos_threshold=3.0

- ru-paraphrase-NMT-Leipzig - синтетический датасет парафразов, созданный с помощью нейронного машинного перевода (NMT):
Берется оригинальный русский текст
Переводится на промежуточный язык (например, английский)
Переводится обратно на русский
Получается парафраз оригинала
В этом датасете только примеры дублей.

- russian-news-paraphrases-2020 (Kaggle) - датасет парафразов русских новостных заголовков за 2020 год
1 = парафраз (дубликат)
0 = не парафраз (не дубликат)

Статистика по собранным датасетам в файлах `view_sources_%`. Вынес отдельно лейпциг, так как будет большое смещение выборки для положительных примеров именно дублей.

3. `train_duplicate_model.py`
Что делает:
Загружает unified_news_pairs.csv (300k+ пар)
Использует sentence-transformers для эмбеддингов
Извлекает 9 признаков (косинусное сходство, расстояния, и т.д.)
Обучает 4 модели (Logistic, RandomForest, GradientBoosting, XGBoost)
Сохраняет в models/*.joblib

4. `predict_duplicates.py` - предсказания
Загружает все модели из models/
Делает предсказания для пары текстов
Показывает результаты от всех моделей + консенсус

5. `validate_models.py`
Валидируем на примерах из предоставленной разметки (то что собрали из согласованных примеров).